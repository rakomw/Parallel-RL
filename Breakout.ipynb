{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parallel_DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omdAAiByyL7L",
        "outputId": "ca88c5cd-f424-4c03-c7d7-0b7f38734ee5"
      },
      "source": [
        "!pip install ray"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray) (0.6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray) (0.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.32.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray) (0.5.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray) (0.10.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.4.post0)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray) (3.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray) (0.3.5)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.12)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (5.4.8)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->ray) (54.2.0)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (3.0.1)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (2.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (20.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.7.4.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (5.1.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (1.26.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (0.1.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (20.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2.4.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgsSAWqHn7NX"
      },
      "source": [
        "import gym\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ray\n",
        "import time\n",
        "\n",
        "from collections      import deque\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import layers"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnFOfh_WPvr4"
      },
      "source": [
        "@ray.remote\n",
        "class ParameterServer(object):\n",
        "    def __init__(self,state_size,action_size):\n",
        "      self.opt = optimizers.Adam(lr=0.001)\n",
        "      self.state_size = state_size \n",
        "      self.action_size = action_size\n",
        "      self.model = self.build_model()\n",
        "      #self.model.set_weights(models.load_model(\"model.h5\").get_weights())\n",
        "\n",
        "    def get_weights(self):\n",
        "      return self.model.get_weights()\n",
        "    \n",
        "    def build_model(self):\n",
        "        model = models.Sequential()\n",
        "      #print(\"Input shape {}\".format(self.state_size))\n",
        "        model.add(layers.Input(shape=self.state_size))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        model.add(layers.Conv2D(32, 8, strides=4, activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64,4,strides=2,activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64, 3, strides=1, activation=\"relu\"))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(512, activation=\"relu\"))\n",
        "        model.add(layers.Dense(self.action_size, activation=\"linear\"))\n",
        "        model.compile(loss='mse', optimizer=self.opt)\n",
        "        return model\n",
        "    \n",
        "    def apply_gradient(self,grad):\n",
        "      var_list = self.model.trainable_variables\n",
        "      self.opt.apply_gradients(zip(grad, var_list))\n",
        "    \n",
        "    def save_weights(self, version):\n",
        "      if (version > 0):\n",
        "        self.model.save(\"savedModels/model{:.0f}.h5\".format(version))\n",
        "      else:\n",
        "        self.model.save(\"model.h5\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jtqx61LPvr6"
      },
      "source": [
        "#handle adding to and sampling from a shared replay memory\n",
        "#only one of these should be created\n",
        "@ray.remote\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self,state_size,action_size):\n",
        "        #deque is an efficient collection for the necessary operations\n",
        "        self.replays = deque(maxlen=100000)\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        \n",
        "    def addMemory(self, state, action, reward, new_state, done):\n",
        "        self.replays.append([state, action, reward, new_state, done])\n",
        "\n",
        "    def sampleReplays(self,batch_size):\n",
        "        #return whatever replays are there if there aren't enough for a full batch\n",
        "        #in practice this shouldn't ever happen\n",
        "        if(len(self.replays) < batch_size):\n",
        "            return np.array(self.replays)\n",
        "        #return a randomly sampled batch from the replay memory\n",
        "        return np.array(random.sample(self.replays, batch_size))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88DN6otoyeKF"
      },
      "source": [
        "@ray.remote(num_gpus=1)\n",
        "class Learner(object):\n",
        "    def __init__(self,param_server,replay_memory,state_size,action_size,batch_size=32,gamma=0.95):\n",
        "        self.param_server = param_server\n",
        "        self.replay_memory = replay_memory\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size \n",
        "        self.sample_batch_size = batch_size\n",
        "        self.gamma = gamma\n",
        "        self.opt = optimizers.Adam(lr=0.001)\n",
        "        #initialize a local copy of Q network\n",
        "        self.Q_network = self.build_model()\n",
        "        #get the weights from parameter server and copy them into local network\n",
        "        self.Q_network.set_weights(ray.get(self.param_server.get_weights.remote()))\n",
        "        #initialize target network from Q network\n",
        "        self.target_network = models.clone_model(self.Q_network)\n",
        "        self.target_network.set_weights(self.Q_network.get_weights())\n",
        "\n",
        "    def build_model(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Input(shape=self.state_size))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        model.add(layers.Conv2D(32, 8, strides=4, activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64,4,strides=2,activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64, 3, strides=1, activation=\"relu\"))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(512, activation=\"relu\"))\n",
        "        model.add(layers.Dense(self.action_size, activation=\"linear\"))\n",
        "        model.compile(loss='mse', optimizer=self.opt)\n",
        "        return model\n",
        "\n",
        "    def learn(self, step,num_batches=1):\n",
        "      for _ in range(num_batches):\n",
        "        #retrieve a batch of replays from the shared memory \n",
        "        mini_batch = ray.get(self.replay_memory.sampleReplays.remote(self.sample_batch_size))\n",
        "        #on the first iteration we'll need to wait until some replays are generated\n",
        "        if (len(mini_batch) < self.sample_batch_size):\n",
        "          return \n",
        "        states = np.zeros((self.sample_batch_size,) + self.state_size)\n",
        "        #print(states.shape)\n",
        "        next_states = np.zeros((self.sample_batch_size,) + self.state_size)\n",
        "        actions, rewards, dones = [], [], []\n",
        "        for i in range(self.sample_batch_size):\n",
        "                states[i] = mini_batch[i][0]\n",
        "                actions.append(mini_batch[i][1])\n",
        "                rewards.append(mini_batch[i][2])\n",
        "                next_states[i] = mini_batch[i][3]\n",
        "                dones.append(mini_batch[i][4])\n",
        "        target =  self.Q_network.predict(states)\n",
        "        target_val = self.target_network.predict(next_states)\n",
        "        for i in range(self.sample_batch_size):\n",
        "                if dones[i]:\n",
        "                    target[i][actions[i]] = rewards[i]\n",
        "                else:\n",
        "                    target[i][actions[i]] = rewards[i] + 0.99 * (\n",
        "                        np.amax(target_val[i]))\n",
        "        \n",
        "        dqn_variable = self.Q_network.trainable_variables\n",
        "        with tf.GradientTape() as tape:  \n",
        "            tape.watch(dqn_variable)\n",
        "            rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
        "            actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
        "            dones = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
        "\n",
        "            target_q = self.target_network(tf.convert_to_tensor(next_states, dtype=tf.float32))\n",
        "            next_action = tf.argmax(target_q, axis=1)\n",
        "            target_value = tf.reduce_sum(tf.one_hot(next_action, self.action_size) * target_q, axis=1)\n",
        "            target_value = (1-dones) * self.gamma * target_value + rewards\n",
        "\n",
        "            main_q = self.Q_network(tf.convert_to_tensor(states, dtype=tf.float32))\n",
        "            main_value = tf.reduce_sum(tf.one_hot(actions, self.action_size) * main_q, axis=1)\n",
        "\n",
        "            loss = tf.math.reduce_mean(tf.square(main_value - target_value))\n",
        "        grad = tape.gradient(loss, dqn_variable)\n",
        "        ray.get(self.param_server.apply_gradient.remote(grad))\n",
        "        #sync weights from parameter server \n",
        "        self.Q_network.set_weights(ray.get(self.param_server.get_weights.remote()))\n",
        "        #sync target network periodically \n",
        "        if (step % 10000) == 0:\n",
        "          self.target_network.set_weights(self.Q_network.get_weights())\n",
        "          print(\"Synced Target Network\")\n",
        "        #print(\"Learning {}\".format(step))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ktgWlNPvr7"
      },
      "source": [
        "@ray.remote \n",
        "class Actor(object):\n",
        "    def __init__(self,param_server,replay_memory,environment):\n",
        "        self.param_server = param_server \n",
        "        self.replay_memory = replay_memory\n",
        "        self.env = environment \n",
        "        self.done = True\n",
        "        self.total_reward = 0\n",
        "        self.episodes = 0\n",
        "        self.state_size = self.env.observation_space.shape\n",
        "        self.action_size = self.env.action_space.n \n",
        "        self.exploration_rate = 1.0\n",
        "        self.exploration_min = 0.1\n",
        "        self.exploration_decay = 0.99995\n",
        "        #make a local copy of the Q-network\n",
        "        self.Q_network = self.build_model()\n",
        "        self.Q_network.set_weights(ray.get(self.param_server.get_weights.remote()))\n",
        "\n",
        "    def build_model(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Input(shape=self.state_size))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        model.add(layers.Conv2D(32, 8, strides=4, activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64,4,strides=2,activation=\"relu\"))\n",
        "        model.add(layers.Conv2D(64, 3, strides=1, activation=\"relu\"))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(512, activation=\"relu\"))\n",
        "        model.add(layers.Dense(self.action_size, activation=\"linear\"))\n",
        "        model.compile()\n",
        "        return model\n",
        "  \n",
        "    def sync_network(self):\n",
        "        self.Q_network.set_weights(ray.get(self.param_server.get_weights.remote()))\n",
        "  \n",
        "    def run_episode(self):\n",
        "        state = self.env.reset()\n",
        "        state = np.expand_dims(state, 0)\n",
        "        total_reward = 0\n",
        "        done = False \n",
        "        while not done:\n",
        "          if np.random.rand() <= self.exploration_rate:\n",
        "            action = random.randrange(self.action_size)\n",
        "          else:\n",
        "            expected_values = self.Q_network.predict(state)\n",
        "            action = np.argmax(expected_values[0])\n",
        "\n",
        "          next_state, reward, done, _ = self.env.step(action)\n",
        "          next_state = np.expand_dims(next_state, 0)\n",
        "          total_reward += reward \n",
        "          ray.get(self.replay_memory.addMemory.remote(state,action,reward,next_state,done))\n",
        "          state = next_state \n",
        "          if self.exploration_rate > self.exploration_min:\n",
        "            self.exploration_rate *= self.exploration_decay\n",
        "\n",
        "        #print(\"Score: {}\".format(total_reward))\n",
        "        return total_reward \n",
        "    def run_step(self):\n",
        "      if self.done:\n",
        "        self.episodes += 1\n",
        "        self.env.close()\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False \n",
        "        episode_reward = self.total_reward \n",
        "        self.total_reward = 0\n",
        "        return episode_reward \n",
        "\n",
        "      state = np.expand_dims(self.state, 0)\n",
        "      if np.random.rand() <= self.exploration_rate:\n",
        "        action = random.randrange(self.action_size)\n",
        "      else:\n",
        "        expected_values = self.Q_network.predict(state)\n",
        "        action = np.argmax(expected_values[0])\n",
        "\n",
        "      next_state, reward, self.done, _ = self.env.step(action)\n",
        "      #next_state = np.expand_dims(next_state, 0)\n",
        "      self.total_reward += reward \n",
        "      ray.get(self.replay_memory.addMemory.remote(state,action,reward,next_state,self.done))\n",
        "      self.state = next_state \n",
        "\n",
        "      if self.exploration_rate > self.exploration_min:\n",
        "        self.exploration_rate *= self.exploration_decay\n",
        "      # wait until episode ends to return total score \n",
        "      #negative result is ignored by caller \n",
        "      return -1\n",
        "    \n",
        "    def get_average(self):\n",
        "      if self.episodes == 0:\n",
        "        return 0\n",
        "      return (self.total_reward / self.episodes)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VzpC8cYQzNk"
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self,env_name,num_actors,num_learners):\n",
        "        self.start_time = time.time()\n",
        "        self.env = gym.make(env_name)\n",
        "        self.state_size = self.env.observation_space.shape\n",
        "        self.action_size = self.env.action_space.n \n",
        "        self.parameter_server = ParameterServer.remote(self.state_size, self.action_size)\n",
        "        self.replay_memory = ReplayMemory.remote(self.state_size, self.action_size)\n",
        "        self.actors = [Actor.remote(self.parameter_server, self.replay_memory, gym.make(env_name)) for _ in range(num_actors)]\n",
        "        self.learners = [Learner.remote(self.parameter_server, self.replay_memory, self.state_size, self.action_size) for _ in range(num_learners)]\n",
        "\n",
        "    def run(self):\n",
        "        counter = 0\n",
        "        high_scores = np.zeros(10)\n",
        "        last_ten = deque(maxlen=10)\n",
        "\n",
        "        while counter < 1000000:\n",
        "          if (counter % 100 == 0):\n",
        "            print(\"Global step {}\".format(counter))\n",
        "            #print(\"Average score {}\".format(np.average(ray.get([actor.get_average.remote() for actor in self.actors]))))\n",
        "            print(\"High scores {}\".format(high_scores))\n",
        "            print(\"Last ten {}\".format(last_ten))\n",
        "            if (counter % 1000 == 0):\n",
        "              print(\"Running for {:.1f} minutes\".format((time.time() - self.start_time) / 60 ))\n",
        "          ray.get([actor.sync_network.remote() for actor in self.actors])\n",
        "          scores = ray.get([actor.run_step.remote() for actor in self.actors])\n",
        "          ray.get([learner.learn.remote(counter) for learner in self.learners])\n",
        "          for score in scores:\n",
        "            # negative score is used as special value \n",
        "            if score >= 0:\n",
        "              last_ten.append(score)\n",
        "            # add high score to the bottom of the list \n",
        "            if score > high_scores[0]: \n",
        "              high_scores[0] = score \n",
        "            # bubble up if necessary \n",
        "            i = 0\n",
        "            j = 1\n",
        "            while (j < len(high_scores)) and (high_scores[i] > high_scores[j]):\n",
        "              temp = high_scores[j]\n",
        "              high_scores[j] = high_scores[i] \n",
        "              high_scores[i] = temp \n",
        "              i += 1\n",
        "              j += 1\n",
        "  \n",
        "          #print(\"Average reward {}\".format(avg_score))\n",
        "          #if avg_score > max_score:\n",
        "            #max_score = avg_score\n",
        "          if (counter % 5000) == 0:\n",
        "            self.save_weights(counter / 5000)\n",
        "          counter += 1\n",
        "\n",
        "    def save_weights(self, suffix):\n",
        "      ray.get(self.parameter_server.save_weights.remote(suffix))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH8plKeeTpMM",
        "outputId": "ef3cab4c-2967-486b-c30e-f67512a939eb"
      },
      "source": [
        "ray.shutdown()\n",
        "ray.init(ignore_reinit_error=True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-14 22:03:55,119\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics_export_port': 60776,\n",
              " 'node_id': '911885bb3e3fe8b6e01a6149e241ea5b4d4f78dc76c18c2b2d7c07a9',\n",
              " 'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2021-04-14_22-03-54_720633_74/sockets/plasma_store',\n",
              " 'raylet_ip_address': '172.28.0.2',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2021-04-14_22-03-54_720633_74/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:6379',\n",
              " 'session_dir': '/tmp/ray/session_2021-04-14_22-03-54_720633_74',\n",
              " 'webui_url': '127.0.0.1:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBFGk3m3Z3D_",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9c80ff-7421-420a-de66-0287b2e2b88b"
      },
      "source": [
        "agent = Agent(\"Breakout-v0\",2,1)\n",
        "agent.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:57.245362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:57.494629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global step 0\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Last ten deque([], maxlen=10)\n",
            "Running for 0.0 minutes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:57.730441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:03:58.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.104722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.105717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110086: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2110)\u001b[0m 2021-04-14 22:03:59.110849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.596326: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.597108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600303: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:03:59.600868: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.946656: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.947408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950699: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b306f4e85e4b\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.950893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:03:59.951248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222140: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.222900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.239899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.240717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.243199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.244768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.245084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.246859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.247719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.248862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249384: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.249492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.250821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.251356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.730475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.731619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:00.732349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"to connect to.\"))\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/workers/default_worker.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   \"--node-ip-address\",\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.370968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.378133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:01.515687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.873181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "\u001b[2m\u001b[36m(pid=2187)\u001b[0m 2021-04-14 22:04:02.881186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.649844: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2108)\u001b[0m 2021-04-14 22:04:30.650218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global step 100\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Last ten deque([0, 0], maxlen=10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.587870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "\u001b[2m\u001b[36m(pid=2111)\u001b[0m 2021-04-14 22:04:39.588247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global step 200\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Last ten deque([0, 0], maxlen=10)\n",
            "Global step 300\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0], maxlen=10)\n",
            "Global step 400\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0], maxlen=10)\n",
            "Global step 500\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0], maxlen=10)\n",
            "Global step 600\n",
            "High scores [0. 0. 0. 0. 0. 0. 0. 0. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0], maxlen=10)\n",
            "Global step 700\n",
            "High scores [0. 0. 0. 0. 0. 0. 1. 1. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 800\n",
            "High scores [0. 0. 0. 0. 0. 0. 1. 1. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 900\n",
            "High scores [0. 0. 0. 0. 0. 0. 1. 1. 2. 2.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 1000\n",
            "High scores [0. 0. 0. 0. 0. 1. 1. 2. 2. 3.]\n",
            "Last ten deque([0, 0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0], maxlen=10)\n",
            "Running for 3.0 minutes\n",
            "Global step 1100\n",
            "High scores [0. 0. 0. 0. 0. 1. 1. 2. 2. 3.]\n",
            "Last ten deque([0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0], maxlen=10)\n",
            "Global step 1200\n",
            "High scores [0. 0. 0. 0. 0. 1. 1. 2. 2. 3.]\n",
            "Last ten deque([2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0], maxlen=10)\n",
            "Global step 1300\n",
            "High scores [0. 0. 0. 0. 0. 1. 1. 2. 2. 3.]\n",
            "Last ten deque([2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0], maxlen=10)\n",
            "Global step 1400\n",
            "High scores [0. 0. 0. 0. 1. 1. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0], maxlen=10)\n",
            "Global step 1500\n",
            "High scores [0. 0. 0. 0. 1. 1. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0], maxlen=10)\n",
            "Global step 1600\n",
            "High scores [0. 0. 1. 1. 1. 1. 2. 2. 3. 3.]\n",
            "Last ten deque([1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 1700\n",
            "High scores [0. 0. 1. 1. 1. 1. 2. 2. 3. 3.]\n",
            "Last ten deque([1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 1800\n",
            "High scores [0. 0. 1. 1. 1. 1. 2. 2. 3. 3.]\n",
            "Last ten deque([1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 1900\n",
            "High scores [0. 1. 1. 1. 1. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 2000\n",
            "High scores [1. 1. 1. 1. 1. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0], maxlen=10)\n",
            "Running for 5.6 minutes\n",
            "Global step 2100\n",
            "High scores [1. 1. 1. 1. 1. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 2200\n",
            "High scores [1. 1. 1. 1. 1. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 2300\n",
            "High scores [1. 1. 1. 1. 2. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0], maxlen=10)\n",
            "Global step 2400\n",
            "High scores [1. 1. 1. 1. 2. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0], maxlen=10)\n",
            "Global step 2500\n",
            "High scores [1. 1. 1. 1. 2. 2. 2. 2. 3. 3.]\n",
            "Last ten deque([3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 2600\n",
            "High scores [1. 1. 1. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0], maxlen=10)\n",
            "Global step 2700\n",
            "High scores [1. 1. 1. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0], maxlen=10)\n",
            "Global step 2800\n",
            "High scores [1. 1. 1. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0], maxlen=10)\n",
            "Global step 2900\n",
            "High scores [1. 1. 1. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 3000\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0], maxlen=10)\n",
            "Running for 8.3 minutes\n",
            "Global step 3100\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0], maxlen=10)\n",
            "Global step 3200\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 3300\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0], maxlen=10)\n",
            "Global step 3400\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 3500\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0], maxlen=10)\n",
            "Global step 3600\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0], maxlen=10)\n",
            "Global step 3700\n",
            "High scores [1. 1. 2. 2. 2. 2. 2. 3. 3. 3.]\n",
            "Last ten deque([1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0], maxlen=10)\n",
            "Global step 3800\n",
            "High scores [1. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0], maxlen=10)\n",
            "Global step 3900\n",
            "High scores [1. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0], maxlen=10)\n",
            "Global step 4000\n",
            "High scores [1. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0], maxlen=10)\n",
            "Running for 11.1 minutes\n",
            "Global step 4100\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 4200\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 4300\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 2.0, 2.0], maxlen=10)\n",
            "Global step 4400\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0], maxlen=10)\n",
            "Global step 4500\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([0.0, 1.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 4600\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([0.0, 1.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 4700\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0], maxlen=10)\n",
            "Global step 4800\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0], maxlen=10)\n",
            "Global step 4900\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0], maxlen=10)\n",
            "Global step 5000\n",
            "High scores [2. 2. 2. 2. 2. 2. 3. 3. 3. 4.]\n",
            "Last ten deque([1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0], maxlen=10)\n",
            "Running for 13.8 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-i317l457gl"
      },
      "source": [
        "agent.save_weights(-1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}