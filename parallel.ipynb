{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parallel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI0pjKHHBqXC"
      },
      "source": [
        "import gym\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "from collections import deque\r\n",
        "import time\r\n",
        "import random\r\n",
        "from multiprocessing import Process, Lock\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYXBGZIBz32"
      },
      "source": [
        "\r\n",
        "# An episode a full game\r\n",
        "train_episodes = 300\r\n",
        "test_episodes = 100\r\n",
        "\r\n",
        "def agent(state_shape, action_shape):\r\n",
        "    \"\"\" The agent maps X-states to Y-actions\r\n",
        "    e.g. The neural network output is [.1, .7, .05, 0.05, .05, .05]\r\n",
        "    The highest value 0.7 is the Q-Value.\r\n",
        "    The index of the highest action (0.7) is action #1.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    learning_rate = 0.001\r\n",
        "    init = tf.keras.initializers.HeUniform()\r\n",
        "    model = keras.Sequential()\r\n",
        "    \r\n",
        "    model.add(keras.layers.Dense(24, input_shape=state_shape, activation='relu', kernel_initializer=init))\r\n",
        "    model.add(keras.layers.Dense(12, activation='relu', kernel_initializer=init))\r\n",
        "    model.add(keras.layers.Dense(action_shape, activation='linear', kernel_initializer=init))\r\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\r\n",
        "    return model\r\n",
        "\r\n",
        "def get_qs(model, state, step):\r\n",
        "    return model.predict(state.reshape([1, state.shape[0]]))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXdzszXtB2gy"
      },
      "source": [
        "def train(env, replay_memory, model, target_model, done):\r\n",
        "    learning_rate = 0.7 # Learning rate\r\n",
        "    discount_factor = 0.618\r\n",
        "\r\n",
        "    MIN_REPLAY_SIZE = 1000\r\n",
        "    if len(replay_memory) < MIN_REPLAY_SIZE:\r\n",
        "        return\r\n",
        "\r\n",
        "    batch_size = 64 * 2\r\n",
        "    mini_batch = random.sample(replay_memory, batch_size)\r\n",
        "    current_states = np.array([encode_observation(transition[0], env.observation_space.shape) for transition in mini_batch])\r\n",
        "    current_qs_list = model.predict(current_states)\r\n",
        "    new_current_states = np.array([encode_observation(transition[3], env.observation_space.shape) for transition in mini_batch])\r\n",
        "    future_qs_list = target_model.predict(new_current_states)\r\n",
        "\r\n",
        "    X = []\r\n",
        "    Y = []\r\n",
        "    for index, (observation, action, reward, new_observation, done) in enumerate(mini_batch):\r\n",
        "        if not done:\r\n",
        "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\r\n",
        "        else:\r\n",
        "            max_future_q = reward\r\n",
        "\r\n",
        "        current_qs = current_qs_list[index]\r\n",
        "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\r\n",
        "\r\n",
        "        X.append(encode_observation(observation, env.observation_space.shape))\r\n",
        "        Y.append(current_qs)\r\n",
        "    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)\r\n",
        "\r\n",
        "def encode_observation(observation, n_dims):\r\n",
        "    return observation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlaOFcK4cl-"
      },
      "source": [
        "env = gym.make('CartPole-v1')\r\n",
        "target_model = agent(env.observation_space.shape, env.action_space.n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_1F_rq8-fRV",
        "outputId": "3c8b9a36-a697-48af-c70d-6ca134f2a20a"
      },
      "source": [
        "print(target_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f55b64afed0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9ViUBPXB9IE"
      },
      "source": [
        "def runit(Lock, lock2):\r\n",
        "    epsilon = 1 # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\r\n",
        "    max_epsilon = 1 # You can't explore more than 100% of the time\r\n",
        "    min_epsilon = 0.01 # At a minimum, we'll always explore 1% of the time\r\n",
        "    decay = 0.01\r\n",
        "    # 1. Initialize the Target and Main models\r\n",
        "    # Main Model (updated every 4 steps)\r\n",
        "    env = gym.make('CartPole-v1')\r\n",
        "    model = agent(env.observation_space.shape, env.action_space.n)\r\n",
        "    # Target Model (updated every 100 steps)\r\n",
        "    with lock2:\r\n",
        "      target_model.set_weights(model.get_weights())\r\n",
        "    \r\n",
        "    replay_memory = deque(maxlen=50_000)\r\n",
        "\r\n",
        "    target_update_counter = 0\r\n",
        "\r\n",
        "    # X = states, y = actions\r\n",
        "    X = []\r\n",
        "    y = []\r\n",
        "\r\n",
        "    steps_to_update_target_model = 0\r\n",
        "\r\n",
        "    for episode in range(train_episodes):\r\n",
        "        total_training_rewards = 0\r\n",
        "        observation = env.reset()\r\n",
        "        done = False\r\n",
        "        while not done:\r\n",
        "            steps_to_update_target_model += 1\r\n",
        "            #if True:\r\n",
        "            #    env.render()\r\n",
        "\r\n",
        "            random_number = np.random.rand()\r\n",
        "            # 2. Explore using the Epsilon Greedy Exploration Strategy\r\n",
        "            if random_number <= epsilon:\r\n",
        "                # Explore\r\n",
        "                action = env.action_space.sample()\r\n",
        "            else:\r\n",
        "                # Exploit best known action\r\n",
        "                # model dims are (batch, env.observation_space.n)\r\n",
        "                encoded = encode_observation(observation, env.observation_space.shape[0])\r\n",
        "                encoded_reshaped = encoded.reshape([1, encoded.shape[0]])\r\n",
        "                predicted = model.predict(encoded_reshaped).flatten()\r\n",
        "                action = np.argmax(predicted)\r\n",
        "            new_observation, reward, done, info = env.step(action)\r\n",
        "            replay_memory.append([observation, action, reward, new_observation, done])\r\n",
        "\r\n",
        "            # 3. Update the Main Network using the Bellman Equation\r\n",
        "            if steps_to_update_target_model % 4 == 0 or done:\r\n",
        "                with lock:\r\n",
        "                  train(env, replay_memory, model, target_model, done)             \r\n",
        "            observation = new_observation\r\n",
        "            total_training_rewards += reward\r\n",
        "\r\n",
        "            if done:\r\n",
        "                print('Total training rewards: {} after n steps = {} with final reward = {}'.format(total_training_rewards, episode, reward))\r\n",
        "                total_training_rewards += 1\r\n",
        "\r\n",
        "                if steps_to_update_target_model >= 100:\r\n",
        "                    print('Copying main network weights to the target network weights')\r\n",
        "                    target_model.set_weights(model.get_weights())\r\n",
        "                    steps_to_update_target_model = 0\r\n",
        "                break\r\n",
        "\r\n",
        "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\r\n",
        "    env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLBO4hqGCweX"
      },
      "source": [
        "import threading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZcgNhMVCta0"
      },
      "source": [
        "class myThread (threading.Thread):\r\n",
        "   def __init__(self, threadID, name, lock,lock2):\r\n",
        "      threading.Thread.__init__(self)\r\n",
        "      self.threadID = threadID\r\n",
        "      self.name = name\r\n",
        "      self.lock = lock\r\n",
        "      self.lock2 = lock2\r\n",
        "   def run(self):\r\n",
        "      print(\"Starting \" + self.name) \r\n",
        "      runit(self.lock,self.lock2)\r\n",
        "      print (\"Exiting \" + self.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5Kduqs5cRF"
      },
      "source": [
        "lock = threading.Lock()\r\n",
        "lock2 = threading.Lock()\r\n",
        "thread1 = myThread(1, \"Thread-1\", lock,lock2)\r\n",
        "thread2 = myThread(2, \"Thread-2\", lock,lock2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-QXoewO9EAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a36966-3bb7-4ded-9fd0-48a2676ebd00"
      },
      "source": [
        "thread1.start()\r\n",
        "thread2.start()\r\n",
        "thread1.join()\r\n",
        "thread2.join()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Thread-1\n",
            "Starting Thread-2\n",
            "Total training rewards: 16.0 after n steps = 0 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 1 with final reward = 1.0\n",
            "Total training rewards: 54.0 after n steps = 2 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 3 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 18.0 after n steps = 4 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 0 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 1 with final reward = 1.0\n",
            "Total training rewards: 22.0 after n steps = 2 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 3 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 5 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 6 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 7 with final reward = 1.0Total training rewards: 29.0 after n steps = 4 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 5 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "\n",
            "Total training rewards: 13.0 after n steps = 8 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 6 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 7 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 8 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 9 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 41.0 after n steps = 9 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 10 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 13.0 after n steps = 10 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 11 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 12 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 13 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 11 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 12 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 13 with final reward = 1.0\n",
            "Total training rewards: 22.0 after n steps = 14 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 14 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 15 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 24.0 after n steps = 15 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 16 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 16 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 16.0 after n steps = 17 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 17 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 18 with final reward = 1.0\n",
            "Total training rewards: 34.0 after n steps = 18 with final reward = 1.0\n",
            "Total training rewards: 27.0 after n steps = 19 with final reward = 1.0\n",
            "Total training rewards: 27.0 after n steps = 19 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 27.0 after n steps = 20 with final reward = 1.0\n",
            "Total training rewards: 37.0 after n steps = 20 with final reward = 1.0\n",
            "Total training rewards: 53.0 after n steps = 21 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 21.0 after n steps = 21 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 22 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 23 with final reward = 1.0\n",
            "Total training rewards: 25.0 after n steps = 22 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 24 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 23 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 24 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 25 with final reward = 1.0\n",
            "Total training rewards: 45.0 after n steps = 25 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 26 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 27 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 26 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 28 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 27 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 29 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 30 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 28 with final reward = 1.0\n",
            "Total training rewards: 25.0 after n steps = 31 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 15.0 after n steps = 29 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 32 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 30 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 31 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 33 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 32 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 34 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 33 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 35 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 34 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 36 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 35 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 37 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 38 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 36 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 39 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 14.0 after n steps = 40 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 41 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 42 with final reward = 1.0\n",
            "Total training rewards: 96.0 after n steps = 37 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 24.0 after n steps = 43 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 38 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 39 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 44 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 40 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 41 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 42 with final reward = 1.0\n",
            "Total training rewards: 32.0 after n steps = 45 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 16.0 after n steps = 43 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 46 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 44 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 47 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 45 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 13.0 after n steps = 48 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 49 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 46 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 50 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 51 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 52 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 53 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 25.0 after n steps = 47 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 48 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 49 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 54 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 50 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 55 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 51 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 56 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 52 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 57 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 53 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 22.0 after n steps = 58 with final reward = 1.0\n",
            "Total training rewards: 23.0 after n steps = 59 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 60 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 43.0 after n steps = 54 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 61 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 55 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 62 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 56 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 63 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 64 with final reward = 1.0\n",
            "Total training rewards: 30.0 after n steps = 57 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 11.0 after n steps = 65 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 58 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 66 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 59 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 67 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 60 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 68 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 61 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 62 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 69 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 70 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 63 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 71 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 64 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 72 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 65 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 8.0 after n steps = 73 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 66 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 74 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 67 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 75 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 76 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 68 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 77 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 69 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 78 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 70 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 79 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 71 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 80 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 72 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 81 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 73 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 74 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 82 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 75 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 83 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 84 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 76 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 85 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 77 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 78 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 86 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 79 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 87 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 80 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 88 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 89 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 81 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 82 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 14.0 after n steps = 90 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 83 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 91 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 84 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 92 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 85 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 93 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 86 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 94 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 87 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 88 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 95 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 89 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 96 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 90 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 97 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 91 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 98 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 92 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 11.0 after n steps = 93 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 99 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 94 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 100 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 95 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 101 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 96 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 102 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 15.0 after n steps = 97 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 103 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 98 with final reward = 1.0\n",
            "Total training rewards: 22.0 after n steps = 104 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 99 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 100 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 101 with final reward = 1.0\n",
            "Total training rewards: 31.0 after n steps = 105 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 102 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 11.0 after n steps = 106 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 103 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 107 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 104 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 108 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 105 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 109 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 106 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 110 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 107 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 111 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 112 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 108 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 109 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 113 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 110 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 114 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 111 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 115 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 112 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 9.0 after n steps = 116 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 113 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 117 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 114 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 118 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 115 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 116 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 119 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 11.0 after n steps = 117 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 120 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 118 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 121 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 119 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 122 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 120 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 121 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 123 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 122 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 13.0 after n steps = 124 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 123 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 125 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 124 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 126 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 125 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 127 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 126 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 128 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 127 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 129 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 128 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 130 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 129 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 130 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 131 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 132 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 131 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 133 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 132 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 14.0 after n steps = 134 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 133 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 134 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 135 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 135 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 136 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 136 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 137 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 9.0 after n steps = 137 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 138 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 138 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 139 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 139 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 140 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 140 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 141 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 141 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 142 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 142 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 15.0 after n steps = 143 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 143 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 144 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 144 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 145 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 145 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 9.0 after n steps = 146 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 146 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 147 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 147 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 148 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 148 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 149 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 150 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 149 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 151 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 150 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 152 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 14.0 after n steps = 151 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 153 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 152 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 154 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 153 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 8.0 after n steps = 155 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 156 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 154 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 157 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 155 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 156 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 158 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 159 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 157 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 160 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 158 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 161 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 162 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 159 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 163 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 160 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 164 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 161 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 165 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 162 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 166 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 167 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 163 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 168 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 169 with final reward = 1.0\n",
            "Total training rewards: 25.0 after n steps = 164 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 170 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 8.0 after n steps = 171 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 172 with final reward = 1.0\n",
            "Total training rewards: 25.0 after n steps = 165 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 11.0 after n steps = 173 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 174 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 166 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 175 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 167 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 176 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 168 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 177 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 169 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 178 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 179 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 170 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 180 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 17.0 after n steps = 171 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 181 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 182 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 172 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 183 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 173 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 184 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 185 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 174 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 175 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 176 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 177 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 31.0 after n steps = 178 with final reward = 1.0\n",
            "Total training rewards: 105.0 after n steps = 186 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 18.0 after n steps = 179 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 187 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 180 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 188 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 189 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 181 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 190 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 182 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 191 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 183 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 9.0 after n steps = 192 with final reward = 1.0\n",
            "Total training rewards: 14.0 after n steps = 193 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 194 with final reward = 1.0\n",
            "Total training rewards: 26.0 after n steps = 184 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 195 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 17.0 after n steps = 185 with final reward = 1.0\n",
            "Total training rewards: 30.0 after n steps = 196 with final reward = 1.0\n",
            "Total training rewards: 27.0 after n steps = 186 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 187 with final reward = 1.0\n",
            "Total training rewards: 26.0 after n steps = 197 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 198 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 188 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 15.0 after n steps = 199 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 189 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 200 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 18.0 after n steps = 190 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 201 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 202 with final reward = 1.0\n",
            "Total training rewards: 23.0 after n steps = 191 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 203 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 204 with final reward = 1.0\n",
            "Total training rewards: 22.0 after n steps = 192 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 205 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 206 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 193 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 207 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 194 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 208 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 12.0 after n steps = 209 with final reward = 1.0\n",
            "Total training rewards: 17.0 after n steps = 195 with final reward = 1.0\n",
            "Total training rewards: 15.0 after n steps = 210 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 196 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 211 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 197 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 198 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 212 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 199 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 26.0 after n steps = 200 with final reward = 1.0\n",
            "Total training rewards: 56.0 after n steps = 213 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 9.0 after n steps = 214 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 201 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 215 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 202 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 216 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 203 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 15.0 after n steps = 217 with final reward = 1.0\n",
            "Total training rewards: 18.0 after n steps = 218 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 204 with final reward = 1.0\n",
            "Total training rewards: 13.0 after n steps = 219 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 23.0 after n steps = 205 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 220 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 221 with final reward = 1.0\n",
            "Total training rewards: 35.0 after n steps = 206 with final reward = 1.0\n",
            "Total training rewards: 20.0 after n steps = 222 with final reward = 1.0\n",
            "Total training rewards: 19.0 after n steps = 207 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 34.0 after n steps = 223 with final reward = 1.0\n",
            "Total training rewards: 39.0 after n steps = 208 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 224 with final reward = 1.0\n",
            "Total training rewards: 24.0 after n steps = 209 with final reward = 1.0\n",
            "Total training rewards: 39.0 after n steps = 225 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 28.0 after n steps = 210 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 226 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 211 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 20.0 after n steps = 227 with final reward = 1.0\n",
            "Total training rewards: 35.0 after n steps = 212 with final reward = 1.0\n",
            "Total training rewards: 21.0 after n steps = 228 with final reward = 1.0\n",
            "Total training rewards: 16.0 after n steps = 229 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 213 with final reward = 1.0\n",
            "Total training rewards: 23.0 after n steps = 230 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 30.0 after n steps = 214 with final reward = 1.0\n",
            "Total training rewards: 32.0 after n steps = 215 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 71.0 after n steps = 231 with final reward = 1.0\n",
            "Total training rewards: 28.0 after n steps = 216 with final reward = 1.0\n",
            "Total training rewards: 8.0 after n steps = 232 with final reward = 1.0\n",
            "Total training rewards: 12.0 after n steps = 233 with final reward = 1.0\n",
            "Total training rewards: 22.0 after n steps = 234 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 41.0 after n steps = 217 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 218 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 45.0 after n steps = 235 with final reward = 1.0\n",
            "Total training rewards: 34.0 after n steps = 219 with final reward = 1.0\n",
            "Total training rewards: 23.0 after n steps = 220 with final reward = 1.0\n",
            "Total training rewards: 42.0 after n steps = 221 with final reward = 1.0\n",
            "Total training rewards: 108.0 after n steps = 236 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 34.0 after n steps = 222 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 24.0 after n steps = 237 with final reward = 1.0\n",
            "Total training rewards: 44.0 after n steps = 223 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 224 with final reward = 1.0\n",
            "Total training rewards: 88.0 after n steps = 238 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 16.0 after n steps = 239 with final reward = 1.0\n",
            "Total training rewards: 57.0 after n steps = 225 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 63.0 after n steps = 240 with final reward = 1.0\n",
            "Total training rewards: 38.0 after n steps = 226 with final reward = 1.0\n",
            "Total training rewards: 37.0 after n steps = 241 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 92.0 after n steps = 227 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 49.0 after n steps = 228 with final reward = 1.0\n",
            "Total training rewards: 108.0 after n steps = 242 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 34.0 after n steps = 229 with final reward = 1.0\n",
            "Total training rewards: 38.0 after n steps = 243 with final reward = 1.0\n",
            "Total training rewards: 40.0 after n steps = 230 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 39.0 after n steps = 231 with final reward = 1.0\n",
            "Total training rewards: 89.0 after n steps = 244 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 36.0 after n steps = 232 with final reward = 1.0\n",
            "Total training rewards: 47.0 after n steps = 245 with final reward = 1.0\n",
            "Total training rewards: 33.0 after n steps = 233 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 246 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 234 with final reward = 1.0\n",
            "Total training rewards: 27.0 after n steps = 247 with final reward = 1.0\n",
            "Total training rewards: 45.0 after n steps = 235 with final reward = 1.0\n",
            "Total training rewards: 50.0 after n steps = 248 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 44.0 after n steps = 236 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 34.0 after n steps = 237 with final reward = 1.0\n",
            "Total training rewards: 111.0 after n steps = 249 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 46.0 after n steps = 238 with final reward = 1.0\n",
            "Total training rewards: 30.0 after n steps = 250 with final reward = 1.0\n",
            "Total training rewards: 47.0 after n steps = 239 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 47.0 after n steps = 240 with final reward = 1.0\n",
            "Total training rewards: 92.0 after n steps = 251 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 50.0 after n steps = 252 with final reward = 1.0\n",
            "Total training rewards: 72.0 after n steps = 241 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 46.0 after n steps = 242 with final reward = 1.0\n",
            "Total training rewards: 87.0 after n steps = 253 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 100.0 after n steps = 243 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 92.0 after n steps = 254 with final reward = 1.0\n",
            "Total training rewards: 42.0 after n steps = 244 with final reward = 1.0\n",
            "Total training rewards: 26.0 after n steps = 255 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 41.0 after n steps = 245 with final reward = 1.0\n",
            "Total training rewards: 59.0 after n steps = 256 with final reward = 1.0\n",
            "Total training rewards: 11.0 after n steps = 257 with final reward = 1.0\n",
            "Total training rewards: 38.0 after n steps = 246 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 34.0 after n steps = 258 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 62.0 after n steps = 247 with final reward = 1.0\n",
            "Total training rewards: 58.0 after n steps = 248 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 109.0 after n steps = 259 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 37.0 after n steps = 260 with final reward = 1.0\n",
            "Total training rewards: 57.0 after n steps = 249 with final reward = 1.0\n",
            "Total training rewards: 76.0 after n steps = 250 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 89.0 after n steps = 261 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 18.0 after n steps = 262 with final reward = 1.0\n",
            "Total training rewards: 48.0 after n steps = 263 with final reward = 1.0\n",
            "Total training rewards: 81.0 after n steps = 251 with final reward = 1.0\n",
            "Total training rewards: 72.0 after n steps = 252 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 94.0 after n steps = 264 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 86.0 after n steps = 265 with final reward = 1.0\n",
            "Total training rewards: 106.0 after n steps = 253 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 78.0 after n steps = 254 with final reward = 1.0\n",
            "Total training rewards: 89.0 after n steps = 266 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 36.0 after n steps = 267 with final reward = 1.0\n",
            "Total training rewards: 65.0 after n steps = 255 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 32.0 after n steps = 268 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 269 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 270 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 271 with final reward = 1.0\n",
            "Total training rewards: 57.0 after n steps = 256 with final reward = 1.0\n",
            "Total training rewards: 40.0 after n steps = 272 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 47.0 after n steps = 257 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 25.0 after n steps = 273 with final reward = 1.0\n",
            "Total training rewards: 51.0 after n steps = 258 with final reward = 1.0\n",
            "Total training rewards: 102.0 after n steps = 274 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 95.0 after n steps = 259 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 106.0 after n steps = 275 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 276 with final reward = 1.0\n",
            "Total training rewards: 80.0 after n steps = 260 with final reward = 1.0\n",
            "Total training rewards: 100.0 after n steps = 261 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 127.0 after n steps = 277 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 35.0 after n steps = 278 with final reward = 1.0\n",
            "Total training rewards: 99.0 after n steps = 262 with final reward = 1.0\n",
            "Total training rewards: 42.0 after n steps = 279 with final reward = 1.0\n",
            "Total training rewards: 53.0 after n steps = 280 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 25.0 after n steps = 281 with final reward = 1.0\n",
            "Total training rewards: 101.0 after n steps = 263 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 10.0 after n steps = 282 with final reward = 1.0\n",
            "Total training rewards: 68.0 after n steps = 283 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 74.0 after n steps = 264 with final reward = 1.0\n",
            "Total training rewards: 74.0 after n steps = 265 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 95.0 after n steps = 284 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 285 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 49.0 after n steps = 286 with final reward = 1.0\n",
            "Total training rewards: 100.0 after n steps = 266 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 31.0 after n steps = 287 with final reward = 1.0\n",
            "Total training rewards: 113.0 after n steps = 267 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 90.0 after n steps = 288 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 37.0 after n steps = 289 with final reward = 1.0\n",
            "Total training rewards: 29.0 after n steps = 290 with final reward = 1.0\n",
            "Total training rewards: 82.0 after n steps = 268 with final reward = 1.0\n",
            "Total training rewards: 32.0 after n steps = 291 with final reward = 1.0\n",
            "Total training rewards: 41.0 after n steps = 292 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 108.0 after n steps = 269 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 102.0 after n steps = 293 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 30.0 after n steps = 294 with final reward = 1.0\n",
            "Total training rewards: 104.0 after n steps = 270 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 32.0 after n steps = 295 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 296 with final reward = 1.0\n",
            "Total training rewards: 10.0 after n steps = 297 with final reward = 1.0\n",
            "Total training rewards: 9.0 after n steps = 298 with final reward = 1.0\n",
            "Total training rewards: 103.0 after n steps = 271 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 36.0 after n steps = 299 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Exiting Thread-2\n",
            "Total training rewards: 91.0 after n steps = 272 with final reward = 1.0\n",
            "Total training rewards: 76.0 after n steps = 273 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 81.0 after n steps = 274 with final reward = 1.0\n",
            "Total training rewards: 94.0 after n steps = 275 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 52.0 after n steps = 276 with final reward = 1.0\n",
            "Total training rewards: 87.0 after n steps = 277 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 44.0 after n steps = 278 with final reward = 1.0\n",
            "Total training rewards: 77.0 after n steps = 279 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 29.0 after n steps = 280 with final reward = 1.0\n",
            "Total training rewards: 101.0 after n steps = 281 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 97.0 after n steps = 282 with final reward = 1.0\n",
            "Total training rewards: 76.0 after n steps = 283 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 77.0 after n steps = 284 with final reward = 1.0\n",
            "Total training rewards: 79.0 after n steps = 285 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 76.0 after n steps = 286 with final reward = 1.0\n",
            "Total training rewards: 96.0 after n steps = 287 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 83.0 after n steps = 288 with final reward = 1.0\n",
            "Total training rewards: 79.0 after n steps = 289 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 81.0 after n steps = 290 with final reward = 1.0\n",
            "Total training rewards: 44.0 after n steps = 291 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 78.0 after n steps = 292 with final reward = 1.0\n",
            "Total training rewards: 183.0 after n steps = 293 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 87.0 after n steps = 294 with final reward = 1.0\n",
            "Total training rewards: 90.0 after n steps = 295 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 88.0 after n steps = 296 with final reward = 1.0\n",
            "Total training rewards: 96.0 after n steps = 297 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Total training rewards: 82.0 after n steps = 298 with final reward = 1.0\n",
            "Total training rewards: 75.0 after n steps = 299 with final reward = 1.0\n",
            "Copying main network weights to the target network weights\n",
            "Exiting Thread-1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}