{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DbLnq8aVmyzH",
        "outputId": "d4a1dd69-615c-4f3a-cf4e-978786dd0944"
      },
      "source": [
        "import gym\r\n",
        "import random\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from multiprocessing  import Process, Queue\r\n",
        "from queue            import Empty\r\n",
        "from collections      import deque\r\n",
        "from keras.models     import Sequential\r\n",
        "from keras.layers     import Dense\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "globalMemory = Queue()\r\n",
        "\r\n",
        "class Agent():\r\n",
        "    def __init__(self, state_size, action_size):\r\n",
        "        self.weight_backup      = \"cartpole_weight.h5\"\r\n",
        "        self.state_size         = state_size\r\n",
        "        self.action_size        = action_size\r\n",
        "        self.memory             = deque(maxlen=2000)\r\n",
        "        self.learning_rate      = 0.001\r\n",
        "        self.gamma              = 0.95\r\n",
        "        self.exploration_rate   = 1.0\r\n",
        "        self.exploration_min    = 0.01\r\n",
        "        self.exploration_decay  = 0.995\r\n",
        "        self.brain              = self._build_model()\r\n",
        "\r\n",
        "    def _build_model(self):\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\r\n",
        "        model.add(Dense(24, activation='relu'))\r\n",
        "        model.add(Dense(self.action_size, activation='linear'))\r\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\r\n",
        "\r\n",
        "        if os.path.isfile(self.weight_backup):\r\n",
        "            model.load_weights(self.weight_backup)\r\n",
        "            self.exploration_rate = self.exploration_min\r\n",
        "        return model\r\n",
        "\r\n",
        "    def save_model(self):\r\n",
        "            self.brain.save(self.weight_backup)\r\n",
        "\r\n",
        "    def act(self, state):\r\n",
        "        if np.random.rand() <= self.exploration_rate:\r\n",
        "            return random.randrange(self.action_size)\r\n",
        "        act_values = self.brain.predict(state)\r\n",
        "        return np.argmax(act_values[0])\r\n",
        "\r\n",
        "    def remember(self, state, action, reward, next_state, done):\r\n",
        "        self.memory.append((state, action, reward, next_state, done))\r\n",
        "        globalMemory.put((state, action, reward, next_state, done))\r\n",
        "\r\n",
        "    def replay(self, sample_batch_size):\r\n",
        "        if globalMemory.qsize() < sample_batch_size:\r\n",
        "            return\r\n",
        "        batch_indexes = set(random.sample(range(globalMemory.qsize()), sample_batch_size))\r\n",
        "        replayCopy = []\r\n",
        "        while True:\r\n",
        "            try:\r\n",
        "                item = globalMemory.get(block=True, timeout=1)\r\n",
        "            except Empty:\r\n",
        "                break\r\n",
        "            else:\r\n",
        "                replayCopy.append(item)\r\n",
        "        for item in replayCopy:\r\n",
        "            globalMemory.put(item)\r\n",
        "        sample_batch = [replayCopy[index] for index in batch_indexes]\r\n",
        "        for state, action, reward, next_state, done in sample_batch:\r\n",
        "            target = reward\r\n",
        "            if not done:\r\n",
        "              target = reward + self.gamma * np.amax(self.brain.predict(next_state)[0])\r\n",
        "            target_f = self.brain.predict(state)\r\n",
        "            target_f[0][action] = target\r\n",
        "            self.brain.fit(state, target_f, epochs=1, verbose=0)\r\n",
        "        if self.exploration_rate > self.exploration_min:\r\n",
        "            self.exploration_rate *= self.exploration_decay\r\n",
        "\r\n",
        "class CartPole:\r\n",
        "    def __init__(self):\r\n",
        "        self.sample_batch_size = 32\r\n",
        "        self.episodes          = 10\r\n",
        "        self.env               = gym.make('CartPole-v1')\r\n",
        "\r\n",
        "        self.state_size        = self.env.observation_space.shape[0]\r\n",
        "        self.action_size       = self.env.action_space.n\r\n",
        "        self.agent             = Agent(self.state_size, self.action_size)\r\n",
        "\r\n",
        "\r\n",
        "    def run(self):\r\n",
        "        try:\r\n",
        "            for index_episode in range(self.episodes):\r\n",
        "                state = self.env.reset()\r\n",
        "                state = np.reshape(state, [1, self.state_size])\r\n",
        "\r\n",
        "                done = False\r\n",
        "                index = 0\r\n",
        "                while not done:\r\n",
        "                    # self.env.render()\r\n",
        "\r\n",
        "                    action = self.agent.act(state)\r\n",
        "\r\n",
        "                    next_state, reward, done, _ = self.env.step(action)\r\n",
        "                    next_state = np.reshape(next_state, [1, self.state_size])\r\n",
        "                    self.agent.remember(state, action, reward, next_state, done)\r\n",
        "                    state = next_state\r\n",
        "                    index += 1\r\n",
        "                print(\"Episode {}# Score: {}\".format(index_episode, index + 1))\r\n",
        "                self.agent.replay(self.sample_batch_size)\r\n",
        "        finally:\r\n",
        "            self.agent.save_model()\r\n",
        "\r\n",
        "def runDQN():\r\n",
        "    cartpole = CartPole()\r\n",
        "    cartpole.run()\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    processes = []\r\n",
        "    for n in range(3):\r\n",
        "        p = Process(target=runDQN, args=())\r\n",
        "        p.name = 'process' + str(n)\r\n",
        "        processes.append(p)\r\n",
        "        \r\n",
        "    for p in processes:\r\n",
        "        p.start()\r\n",
        "    \r\n",
        "    for p in processes:\r\n",
        "        p.join()\r\n",
        "        \r\n",
        "    print(\"Training finished.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0# Score: 19\n",
            "Episode 1# Score: 37\n",
            "Episode 0# Score: 31\n",
            "Episode 1# Score: 25\n",
            "Episode 2# Score: 13\n",
            "Episode 3# Score: 22\n",
            "Episode 0# Score: 20\n",
            "Episode 4# Score: 19\n",
            "Episode 1# Score: 13\n",
            "Episode 5# Score: 17\n",
            "Episode 2# Score: 16\n",
            "Episode 6# Score: 59\n",
            "Episode 3# Score: 14\n",
            "Episode 4# Score: 26\n",
            "Episode 5# Score: 32\n",
            "Episode 7# Score: 14\n",
            "Episode 6# Score: 21\n",
            "Episode 8# Score: 66\n",
            "Episode 7# Score: 24\n",
            "Episode 8# Score: 20\n",
            "Episode 9# Score: 25\n",
            "Episode 9# Score: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process process1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-7b3f4b6ef4da>\", line 113, in runDQN\n",
            "    cartpole.run()\n",
            "  File \"<ipython-input-1-7b3f4b6ef4da>\", line 109, in run\n",
            "    self.agent.save_model()\n",
            "  File \"<ipython-input-1-7b3f4b6ef4da>\", line 40, in save_model\n",
            "    self.brain.save(self.weight_backup)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 2002, in save\n",
            "    signatures, options, save_traces)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\", line 154, in save_model\n",
            "    model, filepath, overwrite, include_optimizer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 108, in save_model_to_hdf5\n",
            "    f = h5py.File(filepath, mode='w')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 408, in __init__\n",
            "    swmr=swmr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 179, in make_fid\n",
            "    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 108, in h5py.h5f.create\n",
            "OSError: Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode 2# Score: 13\n",
            "Episode 3# Score: 14\n",
            "Episode 4# Score: 19\n",
            "Episode 5# Score: 57\n",
            "Episode 6# Score: 14\n",
            "Episode 7# Score: 16\n",
            "Episode 8# Score: 18\n",
            "Episode 9# Score: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process process0:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b3f4b6ef4da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}